{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exploring-preset-agents-overview",
   "metadata": {},
   "source": [
    "# UserProxyAgent Introduction\n",
    "\n",
    "## Overview\n",
    "\n",
    "We covered `UserProxyAgent` in the previous section.  It is repeated here for your convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisites",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Ensure you have the necessary packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9b6d66-35bc-4ba7-9c27-28762fae34ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --quiet -U \"autogen-agentchat>=0.7\" \"autogen-ext[openai]>=0.7\" rich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a675615-180f-4156-9ab5-8db7b5f593da",
   "metadata": {},
   "source": [
    "Note: Some agents require additional dependencies, which are included in the `autogen-ext` extras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "user-proxy-agent",
   "metadata": {},
   "source": [
    "## `UserProxyAgent`\n",
    "\n",
    "The `UserProxyAgent` is designed to simulate a human user. It takes user input and returns it as responses, often acting as the entry point for a conversation or a proxy for human feedback and intervention in multi-agent systems.\n",
    "\n",
    "We haven't covered teams - this will be covered in a later tutorial.  For now just think of a team as multiple agents that work together until some termination criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "user-proxy-agent-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Conversation with UserProxyAgent:\n",
      "----------------------------------------\n",
      "---------- TextMessage (user) ----------\n",
      "Tell me a joke.\n",
      "---------- TextMessage (assistant) ----------\n",
      "Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your response:  what do you call a donkey with three legs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user_proxy) ----------\n",
      "what do you call a donkey with three legs\n",
      "---------- TextMessage (assistant) ----------\n",
      "A wonky donkey!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your response:  TERMINATE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user_proxy) ----------\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import UserProxyAgent, AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "async def run_user_proxy_example():\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "    \n",
    "    # The assistant agent\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        model_client=model_client,\n",
    "        system_message=\"You are a helpful AI assistant.\"\n",
    "    )\n",
    "    \n",
    "    # The user proxy agent\n",
    "    user_proxy = UserProxyAgent(\n",
    "        name=\"user_proxy\",\n",
    "    )\n",
    "    \n",
    "    print(\"\\nðŸ”„ Conversation with UserProxyAgent:\")\n",
    "    print(\"Enter TERMINATE to exit.\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "    from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "    \n",
    "    # Create a team with termination condition\n",
    "    team = RoundRobinGroupChat(\n",
    "        participants=[assistant, user_proxy],\n",
    "        termination_condition=TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(max_messages=5)\n",
    "    )\n",
    "    \n",
    "    # Run the team conversation\n",
    "    await Console(team.run_stream(task=\"Tell me a joke.\"))    \n",
    "    await model_client.close()\n",
    "\n",
    "await run_user_proxy_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
