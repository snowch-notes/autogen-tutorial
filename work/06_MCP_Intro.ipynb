{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial-intro",
   "metadata": {},
   "source": [
    "# AutoGen with MCP Built-in Echo Server Tutorial\n",
    "\n",
    "This notebook demonstrates how to use AutoGen with the Model Context Protocol (MCP) using the built-in Python echo server.\n",
    "\n",
    "## What is MCP?\n",
    "\n",
    "The Model Context Protocol (MCP) allows AI agents to access external tools and data sources in a standardized way. Think of it as a universal connector that lets your AI agent use various tools like file systems, databases, APIs, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisites",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install --quiet -U \"autogen-agentchat>=0.7\" \"autogen-ext[openai,mcp]>=0.7\" \"mcp>=1.0.0\"\n",
    "\n",
    "# IMPORTANT: See: https://github.com/microsoft/autogen/issues/6906\n",
    "!pip install --quiet --force-reinstall \"openai==1.80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e79e01-7a08-4867-b894-a7bc3b194af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_echo_tool.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_echo_tool.py\n",
    "\"\"\"\n",
    "FastMCP Echo Server with Logging\n",
    "\"\"\"\n",
    "import logging\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Create server\n",
    "mcp = FastMCP(\"Echo Server\")\n",
    "\n",
    "@mcp.tool()\n",
    "def echo(text: str) -> str:\n",
    "    \"\"\"Echo the input text\"\"\"\n",
    "    logging.info(f\"ECHO TOOL CALLED with text: '{text}'\")\n",
    "    return text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"Starting Echo Server...\")\n",
    "    mcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5321cfe1-5ff8-42a0-9eec-9a893fcaf933",
   "metadata": {},
   "source": [
    "```bash\n",
    "sudo apt-get update\n",
    "sudo apt-get install npm\n",
    "pip install uv mcp[cli]\n",
    "python mcp_echo_tool.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-header",
   "metadata": {},
   "source": [
    "## Step 1: Verify MCP Echo Server\n",
    "\n",
    "Let's first verify that the built-in echo server is available:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-header",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Your OpenAI API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-header",
   "metadata": {},
   "source": [
    "## Step 3: Create a Simple AutoGen Agent with MCP Echo Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "autogen-mcp-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Task 1: Use the echo tool to say 'Hello, MCP World!'\n",
      "----------------------------------------\n",
      "---------- TextMessage (user) ----------\n",
      "Use the echo tool to say 'Hello, MCP World!'\n",
      "---------- ToolCallRequestEvent (echo_assistant) ----------\n",
      "[FunctionCall(id='call_vLmJpewMS6gEj6ComWMfWM3S', arguments='{\"text\":\"Hello, MCP World!\"}', name='echo')]\n",
      "---------- ToolCallExecutionEvent (echo_assistant) ----------\n",
      "[FunctionExecutionResult(content='[{\"type\": \"text\", \"text\": \"Hello, MCP World!\", \"annotations\": null}]', name='echo', call_id='call_vLmJpewMS6gEj6ComWMfWM3S', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (echo_assistant) ----------\n",
      "[{\"type\": \"text\", \"text\": \"Hello, MCP World!\", \"annotations\": null}]\n",
      "\n",
      "üîÑ Task 2: Echo back 'AutoGen + MCP is awesome!'\n",
      "----------------------------------------\n",
      "---------- TextMessage (user) ----------\n",
      "Echo back 'AutoGen + MCP is awesome!'\n",
      "---------- ToolCallRequestEvent (echo_assistant) ----------\n",
      "[FunctionCall(id='call_MJlpK5TGR5AmRx01fvMirKOq', arguments='{\"text\":\"AutoGen + MCP is awesome!\"}', name='echo')]\n",
      "---------- ToolCallExecutionEvent (echo_assistant) ----------\n",
      "[FunctionExecutionResult(content='[{\"type\": \"text\", \"text\": \"AutoGen + MCP is awesome!\", \"annotations\": null}]', name='echo', call_id='call_MJlpK5TGR5AmRx01fvMirKOq', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (echo_assistant) ----------\n",
      "[{\"type\": \"text\", \"text\": \"AutoGen + MCP is awesome!\", \"annotations\": null}]\n",
      "\n",
      "üîÑ Task 3: Can you echo 'This is working perfectly'?\n",
      "----------------------------------------\n",
      "---------- TextMessage (user) ----------\n",
      "Can you echo 'This is working perfectly'?\n",
      "---------- ToolCallRequestEvent (echo_assistant) ----------\n",
      "[FunctionCall(id='call_p1l0k48Xtgizc5xuhropczjE', arguments='{\"text\":\"This is working perfectly\"}', name='echo')]\n",
      "---------- ToolCallExecutionEvent (echo_assistant) ----------\n",
      "[FunctionExecutionResult(content='[{\"type\": \"text\", \"text\": \"This is working perfectly\", \"annotations\": null}]', name='echo', call_id='call_p1l0k48Xtgizc5xuhropczjE', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (echo_assistant) ----------\n",
      "[{\"type\": \"text\", \"text\": \"This is working perfectly\", \"annotations\": null}]\n"
     ]
    }
   ],
   "source": [
    "# AutoGen with MCP Echo Server\n",
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.mcp import McpWorkbench, StreamableHttpServerParams, StreamableHttpMcpToolAdapter\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "async def run_echo_example():\n",
    "    \"\"\"Run the AutoGen MCP echo server example\"\"\"\n",
    "    \n",
    "    # Define the MCP echo server\n",
    "    server_params = StreamableHttpServerParams(\n",
    "        url=\"http://127.0.0.1:8000/mcp\"\n",
    "    )\n",
    "    adapter = await StreamableHttpMcpToolAdapter.from_server_params(server_params, \"echo\")\n",
    "    \n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "    \n",
    "    # Create assistant agent with MCP tools\n",
    "    agent = AssistantAgent(\n",
    "        name=\"echo_assistant\",\n",
    "        model_client=model_client,\n",
    "        tools=[adapter],\n",
    "        system_message=\"You are a helpful assistant that can use the echo tool to repeat messages back to users.\"\n",
    "    )\n",
    "    \n",
    "    # Test the echo functionality\n",
    "    tasks = [\n",
    "        \"Use the echo tool to say 'Hello, MCP World!'\",\n",
    "        \"Echo back 'AutoGen + MCP is awesome!'\",\n",
    "        \"Can you echo 'This is working perfectly'?\"\n",
    "    ]\n",
    "    \n",
    "    for i, task in enumerate(tasks, 1):\n",
    "        print(f\"\\nüîÑ Task {i}: {task}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        await Console(\n",
    "            agent.run_stream(task=task, cancellation_token=CancellationToken())\n",
    "        )\n",
    "        \n",
    "    await model_client.close()\n",
    "\n",
    "await run_echo_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-header",
   "metadata": {},
   "source": [
    "## Step 4: Understanding What Happened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff60fa-db54-4dd7-984f-c5ea82e60e29",
   "metadata": {},
   "source": [
    "üîç What just happened?\n",
    "\n",
    "1. **MCP Server Setup**: We created a StdioServerParams that points to the built-in echo server.\n",
    "   \n",
    "2. **Workbench Connection**: McpWorkbench manages the connection between AutoGen and the MCP server.\n",
    "   \n",
    "3. **Agent Creation**: Our AssistantAgent was configured to use the workbench, giving it access to the server's tools.\n",
    "   \n",
    "4. **Tool Usage**: The agent automatically discovered and used the 'echo' tool when prompted.\n",
    "\n",
    "The echo server provides a simple tool that takes a message and echoes it back.\n",
    "This demonstrates the basic MCP workflow: Agent ‚Üí MCP Client ‚Üí MCP Server ‚Üí Tool ‚Üí Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps-header",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d335df59-b58d-4a29-86ed-4ea6b1c35e60",
   "metadata": {},
   "source": [
    "\n",
    "üéâ Congratulations! You've successfully:\n",
    "\n",
    "‚úÖ Set up AutoGen with MCP\n",
    "‚úÖ Connected to a built-in Python MCP server  \n",
    "‚úÖ Created an agent that can use MCP tools\n",
    "‚úÖ Tested the echo functionality\n",
    "\n",
    "üöÄ Next Steps:\n",
    "\n",
    "1. **Try Other Built-in Servers**:\n",
    "   - Memory server: python -m mcp_sdk.mcp_client.examples.memory\n",
    "   - SQLite server: python -m mcp_sdk.mcp_client.examples.sqlite\n",
    "\n",
    "2. **Create Custom MCP Servers**:\n",
    "   - Use FastMCP for simpler Python servers\n",
    "   - Implement your own tools and capabilities\n",
    "\n",
    "3. **Explore Community Servers**:\n",
    "   - File system operations\n",
    "   - Web scraping tools  \n",
    "   - Database integrations\n",
    "   - API connectors\n",
    "\n",
    "4. **Build Real Applications**:\n",
    "   - Data analysis agents\n",
    "   - File processing workflows\n",
    "   - Multi-agent systems with shared tools\n",
    "\n",
    "üìö Resources:\n",
    "- MCP Documentation: https://modelcontextprotocol.io\n",
    "- AutoGen Documentation: https://microsoft.github.io/autogen\n",
    "- Python MCP SDK: https://github.com/modelcontextprotocol/python-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial showed you how to integrate AutoGen with MCP using the built-in echo server. The echo server is perfect for learning because it's simple but demonstrates all the key MCP concepts:\n",
    "\n",
    "- **Server Connection**: How AutoGen connects to MCP servers\n",
    "- **Tool Discovery**: How agents find available tools\n",
    "- **Tool Usage**: How agents invoke MCP tools automatically\n",
    "- **Response Handling**: How results flow back to the agent\n",
    "\n",
    "The same patterns work with any MCP server - file systems, databases, APIs, or custom tools you build yourself!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
